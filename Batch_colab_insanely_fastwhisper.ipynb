
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNO3mkZ+HMQrvkMHRtFpKvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhavs10/insanely-fast-whisper/blob/main/insanely_fast_whisper_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    }
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glevilla/Batch_colab_insanely_fastwhisper/blob/main/Batch_colab_insanely_fastwhisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    }
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transcription automatique en lot de documents audios\n",
        "\n",
        "Ce notebook permet de transcrire automatiquement tous les fichiers audio dans un dossier sp√©cifi√© en utilisant Insanely Fast Whisper sans aucun besoin de compr√©hension du code. Les fichiers seront tri√©s dans des sous-dossiers selon le succ√®s ou l'√©chec de la transcription.\n",
        "\n",
        "Voici les √©tapes √† respecter :\n",
        "\n",
        "\n",
        "1.   **Placer les fichiers audio dans un dossier de votre Google drive**.\n",
        "2.   **Ex√©cutez les cellules A et B** en autorisant les modifications sur votre Google Drive. Appuyez sur les fl√®ches en surbrillance dans le coin en haut √† gauche des cellules. Les cellules sont les blocs contenant du code √† gauche des instructions.\n",
        "3.   **Dans la cellule C**, indiquez les param√®tres n√©cessaires √† la retranscription, notamment:\n",
        "    *   Le chemin d'acc√®s de votre dossier Google Drive (la racine est \"/content/drive/MyDrive/\", ajoutez le nom du dossier √† la fin de ce chemin).\n",
        "    *   Vous pouvez activer la diarisation, c'est-√†-dire la reconnaissance des diff√©rents interlocuteurs, tr√®s pratique pour retranscrire un entretien.\n",
        "        *   Pour cela, vous devez cr√©er un compte sur Hugging Face (gratuit), cr√©er un token \"read\" (cl√© d'authentification de votre compte Hugging Face), et accepter les conditions d'utilisation sur chacune des pages du package Pyannote.audio (instructions d√©taill√©es dans la cellule C).\n",
        "4.   **Ex√©cutez la cellule D.**\n",
        "5.   **Ex√©cutez la cellule E.** Deux boutons s'affichent :\n",
        "    *   Le premier bouton lance une retranscription de tous les fichiers audio (au premier lancement, l'installation du mod√®le de reconnaissance est longue).\n",
        "    *   Le deuxi√®me bouton convertit les fichiers JSON en fichiers .txt plus faciles √† lire et manipuler.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Un grand merci √† l'√©quipe derri√®re [Insanely Fast Whisper](https://github.com/Vaibhavs10/insanely-fast-whisper) et √†  [Herv√© Br√©din](https://github.com/hbredin) derri√®re pyannote‚Ä§audio.*"
      ],
      "metadata": {
        "id": "q0MBgZKbhdII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### A. Installer les d√©pendances n√©cessaires\n",
        "!pip install -q pipx && apt install python3.10-venv\n",
        "!pipx ensurepath"
      ],
      "metadata": {
        "id": "YdfYekAqb_s3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e1cb5f9f-b359-4fcd-a0a7-20419bae1cad",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.3 [5,716 B]\n",
            "Fetched 2,473 kB in 1s (3,539 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.3_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.3) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.3) ...\n",
            "\u001b[?25lSuccess! Added /root/.local/bin to the PATH environment variable.\n",
            "\n",
            "Consider adding shell completions for pipx. Run 'pipx completions' for instructions.\n",
            "\n",
            "You will need to open a new terminal or re-login for the PATH changes to take effect.\n",
            "\n",
            "Otherwise pipx is ready to go! ‚ú® üåü ‚ú®\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### B. Montage de Google Drive\n",
        "# @markdown Ce colab fonctionne avec Google Drive, il convient de placer tous les fichiers audio dans un dossier sp√©cifique, les fichiers trait√©s seront d√©plac√©s en fonction de la r√©ussite ou l'√©chec de la transcription, et les retranscriptions seront plac√©s dans un dossier *output*.\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "\n",
        "drive_mount_path = Path(\"/content/drive\")\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"MyDrive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAsutABEbvG-",
        "outputId": "c496f85e-1be2-47b6-deaf-0fa50fe972e5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@markdown ### C. Param√®tres de Transcription\n",
        "input_folder = \"/content/drive/MyDrive/Input\" #@param {type:\"string\"}\n",
        "hugging_face_token = \"\" #@param {type:\"string\"}\n",
        "# @markdown Cochez cette case pour activer la diarization (reconnaissance des interlocuteurs) avec le [token Hugging Face](https://huggingface.co/settings/tokens):\n",
        "use_diarization = False #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown V√©rifiez que vous avez accept√© les conditions d'utilisations sur chacune des pages suivantes :\n",
        "# @markdown - [speaker-segmentation](https://huggingface.co/pyannote/speaker-segmentation)\n",
        "# @markdown - [segmentation](https://huggingface.co/pyannote/segmentation)\n",
        "# @markdown - [segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)\n",
        "# @markdown - [voice-activity-detection](https://huggingface.co/pyannote/voice-activity-detection)\n",
        "# @markdown - [overlapped-speech-detection](https://huggingface.co/pyannote/overlapped-speech-detection)\n",
        "# @markdown - [embedding](https://huggingface.co/pyannote/embedding)\n",
        "# @markdown - [speaker-diarization](https://huggingface.co/pyannote/speaker-diarization)\n",
        "# @markdown - [speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n",
        "# @markdown - [speaker-diarization-3.0](https://huggingface.co/pyannote/speaker-diarization-3.0)\n",
        "\n",
        "input_path = Path(input_folder)\n",
        "output_path = input_path / \"output\"  # Cr√©e un sous-dossier pour les sorties √† l'int√©rieur du dossier d'entr√©e\n",
        "input_path.mkdir(parents=True, exist_ok=True)\n",
        "output_path.mkdir(parents=True, exist_ok=True)\n",
        "success_folder = input_path / \"success\"\n",
        "failure_folder = input_path / \"failure\"\n",
        "success_folder.mkdir(exist_ok=True)\n",
        "failure_folder.mkdir(exist_ok=True)\n",
        "\n",
        "def normalize_filenames():\n",
        "    for file in input_path.glob(\"*.*\"):\n",
        "        new_name = file.stem.replace(\" \", \"_\") + file.suffix\n",
        "        file.rename(input_path / new_name)"
      ],
      "metadata": {
        "id": "rs9TdPkgb4jI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### D. D√©finitions des fonctions mobilis√©es dans le script\n",
        "import shutil\n",
        "from subprocess import run\n",
        "import json\n",
        "import re\n",
        "from IPython.display import display\n",
        "\n",
        "def transcribe_audio_files():\n",
        "    normalize_filenames()\n",
        "    for audio_file in input_path.glob(\"*.*\"):\n",
        "        print(f\"Traitement du fichier : {audio_file.name}\")\n",
        "        result_file = output_path / f\"{audio_file.stem}_transcript.json\"\n",
        "        token_option = f\"--hf_token {hugging_face_token}\" if use_diarization else \"\"\n",
        "        command = f\"pipx run insanely-fast-whisper --file-name {audio_file} --transcript-path {result_file} {token_option}\"\n",
        "        result = run(command, shell=True, capture_output=True)\n",
        "\n",
        "        if result.returncode == 0 and result_file.exists():\n",
        "            shutil.move(str(audio_file), str(success_folder / audio_file.name))\n",
        "            print(f\"Transcription r√©ussie pour : {audio_file.name}\")\n",
        "            print(result.stdout)\n",
        "        else:\n",
        "            shutil.move(str(audio_file), str(failure_folder / audio_file.name))\n",
        "            print(f\"√âchec de transcription pour : {audio_file.name}\")\n",
        "            print(\"Erreur retourn√©e par insanely-fast-whisper:\")\n",
        "            print(result.stderr)  # Afficher les erreurs\n",
        "\n",
        "    print(\"Transcription compl√®te. V√©rifiez les dossiers de sortie.\")\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Nettoie le texte en rempla√ßant les espaces multiples par un seul espace.\"\"\"\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def convert_json_to_txt_simple(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    output_text = \"\"\n",
        "    for chunk in data[\"chunks\"]:  # Assumant que la structure JSON contient un champ \"chunks\"\n",
        "        text = chunk[\"text\"]\n",
        "        output_text += text + \" \"\n",
        "    # Nettoyage du texte final avant de l'√©crire dans le fichier\n",
        "    output_text = clean_text(output_text)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(output_text.strip())\n",
        "\n",
        "def convert_json_to_txt_with_speaker(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    output_text = \"\"\n",
        "    current_speaker = None\n",
        "\n",
        "    for chunk in data[\"speakers\"]:  # Assumant que la structure JSON contient un champ \"speakers\"\n",
        "        speaker_id = chunk[\"speaker\"]\n",
        "        text = chunk[\"text\"]\n",
        "\n",
        "        if speaker_id != current_speaker:\n",
        "            output_text += f\"\\n\\n{speaker_id.upper()}\\n\"\n",
        "            current_speaker = speaker_id\n",
        "\n",
        "        output_text += text + \" \"\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(output_text.strip())\n",
        "\n",
        "def convert_all_jsons_in_folder(output_path, conversion_function, suffix):\n",
        "    json_files = list(Path(output_path).glob('*.json'))\n",
        "    for json_file in json_files:\n",
        "        output_file = json_file.with_name(json_file.stem + suffix + '.txt')\n",
        "        conversion_function(json_file, output_file)\n",
        "        print(f\"Converted {json_file} to {output_file}\")\n",
        "\n",
        "# Widgets setup\n",
        "button_conv_simple = widgets.Button(description=\"Convertir le json en txt\")\n",
        "button_conv_speaker = widgets.Button(description=\"Convertir le json en txt avec speaker\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked_simple(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        convert_all_jsons_in_folder(output_path, convert_json_to_txt_simple, '_totxtsimple')\n",
        "        print(\"Conversion simple termin√©e!\")\n",
        "\n",
        "def on_button_clicked_with_speaker(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        convert_all_jsons_in_folder(output_path, convert_json_to_txt_with_speaker, '_withspeaker')\n",
        "        print(\"Conversion avec speaker termin√©e!\")\n",
        "\n",
        "button_conv_simple.on_click(on_button_clicked_simple)\n",
        "button_conv_speaker.on_click(on_button_clicked_with_speaker)\n",
        "\n"
      ],
      "metadata": {
        "id": "hAO4xFwWHc-9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### E. Ex√©cuter la transcription\n",
        "#@markdown En lan√ßant cette cellule, deux boutons s'affichent, *D√©marrer la transcription* et *Convertir le json*. Le premier va retranscrire tous les fichiers audio et vid√©o du dossier input. Les placera dans *failure* en cas d'√©chec, et dans *success* en cas de r√©ussite de la transcription. Il g√©n√®re alors pour chacun des fichiers un fichier au format *.json* souvent p√©nible √† utiliser pour de la retranscription de longs documents. Le second bouton permet de convertir les json en .txt.\n",
        "#@markdown\n",
        "#@markdown Le second bouton est sensible √† l'option de diarization (distinguer les interlocuteurs). La plupart du temps, les √©checs de retranscriptions proviennent d'erreur li√©e au token Hugging Face, il faut s'assurer que celui-ci soit actif sur votre compte Hugging Face et que les conditions d'utilisation sur chacune des pages pyannote ait √©t√© valid√©es. Si l'option de diarization n'est pas coch√©e mais qu'il y a toujours des √©checs de transcriptions, la pr√©sence de musique est peut-√™tre responsable.\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "def run_transcription(b):\n",
        "    display(HTML(\"<b>Normalisation des noms de fichiers...</b>\"))\n",
        "    normalize_filenames()\n",
        "    display(HTML(\"<b>Transcription en cours...</b>\"))\n",
        "    transcribe_audio_files()\n",
        "    display(HTML(\"<b>Transcription termin√©e.</b>\"))\n",
        "button = widgets.Button(description=\"D√©marrer la transcription\")\n",
        "button.on_click(run_transcription)\n",
        "\n",
        "# Affichage du bouton de transcription\n",
        "display(button)\n",
        "# Affichage du bouton et de la sortie\n",
        "display(button_conv_speaker, output) if use_diarization else display(button_conv_simple, output)\n"
      ],
      "metadata": {
        "id": "i_H9Dm89Jj0-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}